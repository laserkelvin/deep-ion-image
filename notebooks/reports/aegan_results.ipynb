{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [8]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 1.279899,
     "end_time": "2021-02-12T18:53:18.331265",
     "exception": false,
     "start_time": "2021-02-12T18:53:17.051366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvin/anaconda3/envs/ion-image/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Checkpoint directory /home/kelvin/Dropbox (MIT)/Projects/deep-ion-image/notebooks/reports exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import peakutils\n",
    "import os\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "from dii.models.base import valid_models\n",
    "from dii.visualization.visualize import radial_profile\n",
    "from dii.pipeline.datautils import get_benchmark_imageset\n",
    "\n",
    "plt.style.use(\"publication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.020857,
     "end_time": "2021-02-12T18:53:18.367035",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.346178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_profile_peaks(x: np.ndarray, y: np.ndarray, thres=0.05):\n",
    "    idx = peakutils.indexes(y, thres=thres)\n",
    "    centers = peakutils.interpolate(x, y, ind=idx)\n",
    "    return idx, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015859,
     "end_time": "2021-02-12T18:53:18.397085",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.381226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model testing report\n",
    "\n",
    "This notebook is generated using `papermill`.\n",
    "\n",
    "## Parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.022228,
     "end_time": "2021-02-12T18:53:18.434787",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.412559",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameter cell; do not edit!\n",
    "model_kwargs = {\n",
    "    \"in_channels\": 1,\n",
    "    \"out_channels\": 1,\n",
    "    \"latent_dim\": 64,\n",
    "    \"activation\": \"silu\"\n",
    "}\n",
    "image_index = 50\n",
    "models_path = \"../../models/\"\n",
    "benchmark_path = \"../../data/processed\"\n",
    "n_images = 128\n",
    "model_name = \"baseline\"\n",
    "probabilistic = False\n",
    "img_center = (64, 64)\n",
    "output_root = \"outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.020028,
     "end_time": "2021-02-12T18:53:18.469825",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.449797",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model_kwargs = {\n",
    "    \"in_channels\": 1,\n",
    "    \"out_channels\": 1,\n",
    "    \"latent_dim\": 128,\n",
    "    \"activation\": \"silu\",\n",
    "}\n",
    "probabilistic = False\n",
    "model_name = \"aegan\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.01881,
     "end_time": "2021-02-12T18:53:18.503076",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.484266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output path is where model specific results go\n",
    "# agg path is a YAML with the combined statistics for summarizing across models\n",
    "output_path = f\"{output_root}{model_name}/\"\n",
    "agg_path = f\"{output_root}combined_statistics.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.018853,
     "end_time": "2021-02-12T18:53:18.536164",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.517311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(output_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014539,
     "end_time": "2021-02-12T18:53:18.565078",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.550539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model determination and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.018971,
     "end_time": "2021-02-12T18:53:18.599126",
     "exception": false,
     "start_time": "2021-02-12T18:53:18.580155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figure out what model we are using with the mapping\n",
    "model = valid_models.get(model_name, None)\n",
    "\n",
    "if not model:\n",
    "    raise KeyError(f\"{model_name} is not a valid model in the `dii` codebase! Try again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.315132,
     "end_time": "2021-02-12T18:53:18.928533",
     "exception": true,
     "start_time": "2021-02-12T18:53:18.613401",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_obj = model(**model_kwargs)\n",
    "# model_obj.load_state_dict(torch.load(f\"{models_path}{model_name}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data set loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_images, target_images = get_benchmark_imageset(benchmark_path, n_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    recon = model_obj(input_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Calculating the mean reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "recon_error = F.binary_cross_entropy(recon, target_images).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Mean reconstruction error: {recon_error:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Finding the best and worst images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this calculates the pixelwise loss\n",
    "errors = F.binary_cross_entropy(recon, target_images, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the highest errors to identify which images are worse\n",
    "img_errors = errors.mean((1, 2, 3))\n",
    "worst_idx = torch.argsort(img_errors)[-5:]\n",
    "best_idx = torch.argsort(img_errors)[:5]\n",
    "\n",
    "worst_error = img_errors.max().item()\n",
    "best_error = img_errors.min().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Visualizing the worst images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axarray = plt.subplots(3, 5, figsize=(4, 3), sharex=True, sharey=True)\n",
    "\n",
    "for row, (target, title) in enumerate(zip([input_images, recon, target_images], [\"Input\", \"Reconstruction\", \"Target\"])):\n",
    "    images = target[worst_idx]\n",
    "    for col, image in enumerate(images):\n",
    "        # get rid of the channel dimension\n",
    "        axarray[row, col].imshow(image.squeeze())\n",
    "        axarray[row, col].set(xticks=[], yticks=[])\n",
    "        for _, spine in axarray[row, col].spines.items():\n",
    "            spine.set_visible(False)\n",
    "    axarray[row, 0].set_ylabel(title, rotation=90.)\n",
    "for col, value in enumerate(img_errors[worst_idx]):\n",
    "    axarray[-1, col].set(title=f\"{value:.2f}\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{output_path}{model_name}_worstimgs.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Visualizing the best images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axarray = plt.subplots(3, 5, figsize=(4, 3), sharex=True, sharey=True)\n",
    "\n",
    "for row, (target, title) in enumerate(zip([input_images, recon, target_images], [\"Input\", \"Reconstruction\", \"Target\"])):\n",
    "    images = target[best_idx]\n",
    "    for col, image in enumerate(images):\n",
    "        # get rid of the channel dimension\n",
    "        axarray[row, col].imshow(image.squeeze())\n",
    "        axarray[row, col].set(xticks=[], yticks=[])\n",
    "        for _, spine in axarray[row, col].spines.items():\n",
    "            spine.set_visible(False)\n",
    "    axarray[row, 0].set_ylabel(title, rotation=90.)\n",
    "for col, value in enumerate(img_errors[best_idx]):\n",
    "    axarray[-1, col].set(title=f\"{value:.2f}\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{output_path}{model_name}_bestimgs.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Common ground: compare one image across models\n",
    "\n",
    "### Show what the reconstruction looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axarray = plt.subplots(1, 3, figsize=(2.5, 1), sharex=True, sharey=True)\n",
    "\n",
    "for ax, title, target in zip(axarray, [\"Input\", \"Reconstruction\", \"Target\"], [input_images, recon, target_images]):\n",
    "    ax.imshow(target[image_index].squeeze())\n",
    "    ax.set(title=title, yticks=[], xticks=[])\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{output_path}{model_name}_common_imgs.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Compare radial profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if probabilistic:\n",
    "    # get 200 samples from the posterior\n",
    "    prob_recon = model_obj.predict(input_images[image_index], 200)\n",
    "    prob_profiles = np.vstack([radial_profile(img.squeeze().numpy(), img_center) for img in prob_recon])\n",
    "    # calculate sampling statistics\n",
    "    profile_mean = prob_profiles.mean(axis=0)\n",
    "    normalize = profile_mean.sum()\n",
    "    profile_std = prob_profiles.std(axis=0)\n",
    "    # get +/- one sigma and the mean\n",
    "    upper, lower = (profile_mean + profile_std) / normalize, (profile_mean - profile_std) / normalize\n",
    "    profile_mean /= normalize\n",
    "    df = pd.DataFrame(data=list(zip(profile_mean, upper, lower)), columns=[\"Model\", \"Upper\", \"Lower\"])\n",
    "else:\n",
    "    profile = model_obj.model_radial_profile(input_images[image_index])\n",
    "    profile /= profile.sum()\n",
    "    df = pd.DataFrame(data=profile, columns=[\"Model\"])\n",
    "    \n",
    "for target, name in zip([input_images, target_images], [\"Input\", \"Target\"]):\n",
    "    profile = radial_profile(target[image_index].squeeze().numpy(), img_center)\n",
    "    norm = profile.sum()\n",
    "    profile /= norm\n",
    "    df[name] = profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output the result for overlaying later\n",
    "df.to_csv(f\"{output_path}{model_name}_common_radial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.5, 1.5))\n",
    "\n",
    "colors = [\"#0051ad\", \"#d34e60\", \"#9ac54f\"]\n",
    "\n",
    "for key, color in zip([\"Input\", \"Model\", \"Target\"], colors):\n",
    "    ax.plot(df[key], lw=1., alpha=0.7, label=key, color=color)\n",
    "\n",
    "# if we have a probabilistic model, shade in +/-1 sigma\n",
    "if probabilistic:\n",
    "    ax.fill_between(np.arange(df[\"Model\"].size), df[\"Upper\"], df[\"Lower\"], color=colors[1], alpha=0.4)\n",
    "    \n",
    "ax.set(ylabel=\"$p(r)$\", xlabel=\"Radial distance ($r$ / pixels)\", xlim=[0., img_center[0]])\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{output_path}{model_name}_common_radial.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Radial error quantification\n",
    "\n",
    "__For the sole exemplar image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# true_quant, true_interp = get_profile_peaks(df.index, df[\"Target\"])\n",
    "# recon_quant, recon_interp = get_profile_peaks(df.index, df[\"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# quant_error = (np.square(true_quant - recon_quant)).mean()\n",
    "# interp_error = ((np.square(true_interp - recon_interp)).mean() / df.index.size) * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"Quantized pixel error is {quant_error:.2f} pixels\")\n",
    "# print(f\"Interpolated relative error is {interp_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # see what the centers actually are\n",
    "# print(true_interp, recon_interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "__Across the benchmark set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_num, pred_num = list(), list()\n",
    "kl_divs = list()\n",
    "for target, predicted in zip(target_images, recon):\n",
    "    target_profile = radial_profile(target.squeeze().numpy(), img_center)\n",
    "    recon_profile = radial_profile(predicted.squeeze().numpy(), img_center)\n",
    "    kl = entropy(pk=target_profile, qk=recon_profile)\n",
    "    kl_divs.append(kl)\n",
    "    # get the peaks from the radial profile\n",
    "    x = np.arange(target_profile.size)\n",
    "    true_quant, true_interp = get_profile_peaks(x, target_profile)\n",
    "    recon_quant, recon_interp = get_profile_peaks(x, recon_profile)\n",
    "    true_num.append(len(true_quant))\n",
    "    pred_num.append(len(recon_quant))\n",
    "\n",
    "true_counts, bins = np.histogram(true_num, bins=np.arange(1, 6))\n",
    "pred_counts, bins = np.histogram(pred_num, bins=np.arange(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Mean KL-divergence, representing the true distribution P with the predicted Q: {np.mean(kl_divs):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(figsize=(2.5, 1.5))\n",
    "\n",
    "ax.bar(bins[:-1] - 0.1, true_counts, label=\"True\", alpha=0.7, width=0.2)\n",
    "ax.bar(bins[:-1] + 0.1, pred_counts, label=\"Model\", alpha=0.7, width=0.2)\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "ax.set(ylabel=\"Counts\", xlabel=\"Number of centers detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Finalizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yaml = YAML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "current = None\n",
    "if os.path.isfile(agg_path):\n",
    "    with open(agg_path, \"r\") as results_file:\n",
    "        current = yaml.load(results_file)\n",
    "if not current:\n",
    "    current = dict()\n",
    "current[f\"{model_name}\"] = {\n",
    "    \"kl-divergence\": str(np.mean(kl_divs)),\n",
    "    \"dev_mean_recon\": str(recon_error),\n",
    "    \"best_recon\": str(best_error),\n",
    "    \"worst_recon\": str(worst_error)\n",
    "}\n",
    "with open(agg_path, \"w\") as results_file:\n",
    "    yaml.dump(current, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DII)",
   "language": "python",
   "name": "ion-image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.125693,
   "end_time": "2021-02-12T18:53:19.533707",
   "environment_variables": {},
   "exception": true,
   "input_path": "template.ipynb",
   "output_path": "aegan_results.ipynb",
   "parameters": {
    "model_kwargs": {
     "activation": "silu",
     "in_channels": 1,
     "latent_dim": 128,
     "out_channels": 1
    },
    "model_name": "aegan",
    "probabilistic": false
   },
   "start_time": "2021-02-12T18:53:16.408014",
   "version": "2.3.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
